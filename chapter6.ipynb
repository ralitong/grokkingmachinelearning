{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.7.5)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.20.3)\n",
      "Requirement already satisfied: turicreate in ./.venv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (6.4.1)\n",
      "Requirement already satisfied: ipykernel in ./.venv/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (6.29.5)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (2.4.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (6.4.5)\n",
      "Requirement already satisfied: decorator>=4.0.9 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: pandas>=0.23.2 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (2.0.3)\n",
      "Requirement already satisfied: prettytable==0.7.2 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (0.7.2)\n",
      "Requirement already satisfied: resampy==0.2.1 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (0.2.1)\n",
      "Requirement already satisfied: requests>=2.9.1 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: six>=1.10.0 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: coremltools==4.0b3 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (4.0b3)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: numba<0.51.0 in ./.venv/lib/python3.8/site-packages (from turicreate->-r requirements.txt (line 4)) (0.50.1)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in ./.venv/lib/python3.8/site-packages (from coremltools==4.0b3->turicreate->-r requirements.txt (line 4)) (4.25.5)\n",
      "Requirement already satisfied: attr in ./.venv/lib/python3.8/site-packages (from coremltools==4.0b3->turicreate->-r requirements.txt (line 4)) (0.3.2)\n",
      "Requirement already satisfied: attrs in ./.venv/lib/python3.8/site-packages (from coremltools==4.0b3->turicreate->-r requirements.txt (line 4)) (24.3.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.8/site-packages (from coremltools==4.0b3->turicreate->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.8/site-packages (from coremltools==4.0b3->turicreate->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (1.8.11)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (8.12.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (6.1.1)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.8/site-packages (from ipykernel->-r requirements.txt (line 5)) (5.14.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./.venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 6)) (12.6.85)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 2)) (3.20.2)\n",
      "Requirement already satisfied: backcall in ./.venv/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (0.19.2)\n",
      "Requirement already satisfied: pickleshare in ./.venv/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./.venv/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (4.9.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in ./.venv/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 5)) (8.5.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 5)) (4.3.6)\n",
      "Requirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in ./.venv/lib/python3.8/site-packages (from numba<0.51.0->turicreate->-r requirements.txt (line 4)) (0.33.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.8/site-packages (from numba<0.51.0->turicreate->-r requirements.txt (line 4)) (75.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas>=0.23.2->turicreate->-r requirements.txt (line 4)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.8/site-packages (from pandas>=0.23.2->turicreate->-r requirements.txt (line 4)) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests>=2.9.1->turicreate->-r requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests>=2.9.1->turicreate->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests>=2.9.1->turicreate->-r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests>=2.9.1->turicreate->-r requirements.txt (line 4)) (2024.12.14)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (24.12.23)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (1.68.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (3.11.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.4.13)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.34.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->torch->-r requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.8/site-packages (from sympy->coremltools==4.0b3->turicreate->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.45.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in ./.venv/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (0.2.13)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (2.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (3.0.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.0.0->turicreate->-r requirements.txt (line 4)) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "features = np.array(\n",
    "    [\n",
    "        [1, 0],\n",
    "        [0, 2],\n",
    "        [1, 1],\n",
    "        [1, 2],\n",
    "        [1, 3],\n",
    "        [2, 2],\n",
    "        [2, 3],\n",
    "        [3, 2]\n",
    "    ]\n",
    ")\n",
    "labels = np.array(\n",
    "    [0, 0, 0, 0, 1, 1, 1, 1]\n",
    ")\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.exp(x)/(1 + np.exp(x))\n",
    "\n",
    "\n",
    "def score(weights, bias, features):\n",
    "    return np.dot(weights, features) + bias\n",
    "\n",
    "\n",
    "def prediction(weights, bias, features):\n",
    "    return sigmoid(score(weights, bias, features))\n",
    "\n",
    "# formula for log loss\n",
    "# log loss = -y * ln(y') - (1 - y) ln(1 - y)\n",
    "\n",
    "\n",
    "def log_loss(weights, bias, features, label):\n",
    "    pred = prediction(weights, bias, features)\n",
    "    return -label * np.log(pred) - (1-label) * np.log(1-pred)\n",
    "\n",
    "\n",
    "def total_log_loss(weights, bias, features, labels):\n",
    "    total_error = 0\n",
    "    for i in range(len(features)):\n",
    "        total_error += log_loss(weights, bias, features[i], labels[i])\n",
    "    return total_error\n",
    "\n",
    "\n",
    "def logistic_trick(weights, bias, features, label, learning_rate=0.01):\n",
    "    pred = prediction(weights, bias, features)\n",
    "    for i in range(len(weights)):\n",
    "        feature_i = features[i]\n",
    "        weights[i] += (label - pred) * feature_i * learning_rate\n",
    "        bias += (label - pred) * learning_rate\n",
    "    return weights, bias\n",
    "\n",
    "\n",
    "def logistic_regression(features, labels, learning_rate=0.01, epochs=1000):\n",
    "    utils.plot_points(features, labels)\n",
    "    weights = [1.0 for i in range(len(features[0]))]\n",
    "    bias = 0.0\n",
    "    errors = []\n",
    "    for i in range(epochs):\n",
    "        errors.append(total_log_loss(weights, bias, features, labels))\n",
    "\n",
    "        # randomly select a label and a feature\n",
    "        random_index = random.randint(0, len(features) - 1)\n",
    "        random_feature = features[random_index]\n",
    "        random_label = labels[random_index]\n",
    "\n",
    "        weights, bias = logistic_trick(\n",
    "            weights, bias, random_feature, random_label, learning_rate)\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights, bias = logistic_regression(features, labels)\n",
    "a = weights[0]\n",
    "b = weights[1]\n",
    "c = bias\n",
    "utils.draw_line(a, b, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ubuntu/grokkingmachinelearning/IMDB_Dataset.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ubuntu/grokkingmachinelearning/IMDB_Dataset.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.213641 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.213641 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 39624 lines. Lines per second: 117053</pre>"
      ],
      "text/plain": [
       "Read 39624 lines. Lines per second: 117053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ubuntu/grokkingmachinelearning/IMDB_Dataset.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ubuntu/grokkingmachinelearning/IMDB_Dataset.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 50000 lines in 0.396218 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 50000 lines in 0.396218 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 47500</pre>"
      ],
      "text/plain": [
       "Number of examples          : 47500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 1</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 101843</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 101843"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients      : 101844</pre>"
      ],
      "text/plain": [
       "Number of coefficients      : 101844"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 0         | 2        | 1.000000  | 0.154060     | 0.917326          | 0.856400            |</pre>"
      ],
      "text/plain": [
       "| 0         | 2        | 1.000000  | 0.154060     | 0.917326          | 0.856400            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 4        | 1.000000  | 0.278981     | 0.939958          | 0.862800            |</pre>"
      ],
      "text/plain": [
       "| 1         | 4        | 1.000000  | 0.278981     | 0.939958          | 0.862800            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 6        | 0.837855  | 0.399817     | 0.971474          | 0.893600            |</pre>"
      ],
      "text/plain": [
       "| 2         | 6        | 0.837855  | 0.399817     | 0.971474          | 0.893600            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 7        | 1.000000  | 0.484331     | 0.980042          | 0.899200            |</pre>"
      ],
      "text/plain": [
       "| 3         | 7        | 1.000000  | 0.484331     | 0.980042          | 0.899200            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 8        | 1.000000  | 0.576968     | 0.987179          | 0.903600            |</pre>"
      ],
      "text/plain": [
       "| 4         | 8        | 1.000000  | 0.576968     | 0.987179          | 0.903600            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 9         | 13       | 1.000000  | 1.008674     | 0.999684          | 0.877200            |</pre>"
      ],
      "text/plain": [
       "| 9         | 13       | 1.000000  | 1.008674     | 0.999684          | 0.877200            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">class</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">value</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">stderr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">(intercept)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.12386796751211071</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">darker</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5510589231985</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">touch</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.20830008354686988</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">thats</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.4658444638029298</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">your</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.019654334689209397</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">viewing</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.10272382942533444</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">their</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.00758310340427383</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">into</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.006225691572922391</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">turned</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.18587497138293455</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">words</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">being</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.015099321136843383</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[101844 rows x 5 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tclass\tstr\n",
       "\tvalue\tfloat\n",
       "\tstderr\tfloat\n",
       "\n",
       "Rows: 101844\n",
       "\n",
       "Data:\n",
       "+-------------+---------+----------+-----------------------+--------+\n",
       "|     name    |  index  |  class   |         value         | stderr |\n",
       "+-------------+---------+----------+-----------------------+--------+\n",
       "| (intercept) |   None  | positive |  0.12386796751211071  |  None  |\n",
       "|    words    |  darker | positive |    0.5510589231985    |  None  |\n",
       "|    words    |  touch  | positive |  0.20830008354686988  |  None  |\n",
       "|    words    |  thats  | positive |  -0.4658444638029298  |  None  |\n",
       "|    words    |   your  | positive | -0.019654334689209397 |  None  |\n",
       "|    words    | viewing | positive |  0.10272382942533444  |  None  |\n",
       "|    words    |  their  | positive |  0.00758310340427383  |  None  |\n",
       "|    words    |   into  | positive | -0.006225691572922391 |  None  |\n",
       "|    words    |  turned | positive |  -0.18587497138293455 |  None  |\n",
       "|    words    |  being  | positive | -0.015099321136843383 |  None  |\n",
       "+-------------+---------+----------+-----------------------+--------+\n",
       "[101844 rows x 5 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import turicreate as tc\n",
    "movies = tc.SFrame('IMDB_Dataset.csv')\n",
    "movies['words'] = tc.text_analytics.count_words(movies['review'])\n",
    "\n",
    "model = tc.logistic_classifier.create(movies, features=['words'], target='sentiment')\n",
    "model.coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"This is an Oriental fantasy about thousand and one Arabian nights plenty of incredible adventures, fantasy witchery and wizardly. The malignant vizier Jaffar (magnificently played by Conrad Veidt)with powerful magic faculties imprisons the prince Ahamad of Bagdad(attractive John Justin)who loses his throne, then he escapes thanks a little thief named Abu(sympathetic Sabu). They arrive Basora where Ahamad and the princess(gorgeous June Duprez) fall in love. But prince and thief are haunted by Jaffar , Ahamd is turned blind and Abu is become a dog. The story accumulates several fantastic ingredients such as transformation of the starring, a flying mechanic horse, magic bow, flying carpet and of course the colossal genie(overacting performed by Rex Ingram) who gives three wishes to Sabu , the magic eye, the figure of goddess Kali with several hands, among others.<br /><br />This remarkable picture ranks as one of the finest fantastic films of all time. Produced by London Fim's Alexander Korda and directed by the definitively credited Ludwing Berger, Michael Powell and Tim Whelan with a stunning screenplay by Lajos Biro and Miles Malleson also dialogs writer and actor as Sultan fond to mechanic games. The WWII outbreak caused the paralyzing shooting, then the three Korda brothers and collaborators traveled USA continuing there the filming in especial on Grand Cannon Colorado.The splendid visual and glimmer Technicolor cinematography , setting and FX provoked the achieving three Oscars : Production design by William Cameron Menzies and Vincent Korda ,Cinematography by George Perinal and Special effects by Osmond Borradaile though today are dated and is urgent a necessary remastering because the colors are worn-out. Furthermore one nomination for the evocative and oriental musical score by Miklos Rozsa. This vivid tale with immense doses of imagination will like to fantasy fans and cinema classic buffs\",\n",
       " 'sentiment': 'positive',\n",
       " 'words': {'classic': 1.0,\n",
       "  'cinema': 1.0,\n",
       "  'like': 1.0,\n",
       "  'will': 1.0,\n",
       "  'imagination': 1.0,\n",
       "  'doses': 1.0,\n",
       "  'eye': 1.0,\n",
       "  'princess': 1.0,\n",
       "  'carpet': 1.0,\n",
       "  'games': 1.0,\n",
       "  'ingram': 1.0,\n",
       "  'overacting': 1.0,\n",
       "  'credited': 1.0,\n",
       "  'miles': 1.0,\n",
       "  'flying': 2.0,\n",
       "  'transformation': 1.0,\n",
       "  'story': 1.0,\n",
       "  'brothers': 1.0,\n",
       "  'dog': 1.0,\n",
       "  'become': 1.0,\n",
       "  'ingredients': 1.0,\n",
       "  'are': 3.0,\n",
       "  'in': 2.0,\n",
       "  'starring': 1.0,\n",
       "  'conrad': 1.0,\n",
       "  'june': 1.0,\n",
       "  'as': 3.0,\n",
       "  'gorgeous': 1.0,\n",
       "  'ahamad': 2.0,\n",
       "  'vivid': 1.0,\n",
       "  'love': 1.0,\n",
       "  'where': 1.0,\n",
       "  'they': 1.0,\n",
       "  'nights': 1.0,\n",
       "  'basora': 1.0,\n",
       "  'escapes': 1.0,\n",
       "  'continuing': 1.0,\n",
       "  'witchery': 1.0,\n",
       "  'evocative': 1.0,\n",
       "  'of': 8.0,\n",
       "  'effects': 1.0,\n",
       "  'wishes': 1.0,\n",
       "  'john': 1.0,\n",
       "  'for': 1.0,\n",
       "  'oriental': 2.0,\n",
       "  'berger': 1.0,\n",
       "  'lajos': 1.0,\n",
       "  'wizardly': 1.0,\n",
       "  'magnificently': 1.0,\n",
       "  'an': 1.0,\n",
       "  'all': 1.0,\n",
       "  'accumulates': 1.0,\n",
       "  'to': 3.0,\n",
       "  'fantasy': 3.0,\n",
       "  'genie': 1.0,\n",
       "  'thousand': 1.0,\n",
       "  'duprez': 1.0,\n",
       "  'his': 1.0,\n",
       "  'glimmer': 1.0,\n",
       "  'adventures': 1.0,\n",
       "  'horse': 1.0,\n",
       "  'one': 3.0,\n",
       "  'played': 1.0,\n",
       "  'such': 1.0,\n",
       "  'alexander': 1.0,\n",
       "  'faculties': 1.0,\n",
       "  'attractive': 1.0,\n",
       "  'several': 2.0,\n",
       "  'turned': 1.0,\n",
       "  'about': 1.0,\n",
       "  'provoked': 1.0,\n",
       "  'three': 3.0,\n",
       "  'jaffar': 2.0,\n",
       "  'london': 1.0,\n",
       "  'sultan': 1.0,\n",
       "  'arabian': 1.0,\n",
       "  'prince': 2.0,\n",
       "  'gives': 1.0,\n",
       "  'achieving': 1.0,\n",
       "  'goddess': 1.0,\n",
       "  'named': 1.0,\n",
       "  'veidt': 1.0,\n",
       "  'course': 1.0,\n",
       "  'incredible': 1.0,\n",
       "  'and': 18.0,\n",
       "  'powerful': 1.0,\n",
       "  'today': 1.0,\n",
       "  'justin': 1.0,\n",
       "  'fall': 1.0,\n",
       "  'because': 1.0,\n",
       "  'though': 1.0,\n",
       "  'by': 10.0,\n",
       "  'magic': 3.0,\n",
       "  'imprisons': 1.0,\n",
       "  'produced': 1.0,\n",
       "  'out': 1.0,\n",
       "  'arrive': 1.0,\n",
       "  'korda': 3.0,\n",
       "  'loses': 1.0,\n",
       "  'bagdad': 1.0,\n",
       "  'malignant': 1.0,\n",
       "  'fans': 1.0,\n",
       "  'films': 1.0,\n",
       "  'cameron': 1.0,\n",
       "  'sabu': 2.0,\n",
       "  'actor': 1.0,\n",
       "  'who': 2.0,\n",
       "  'a': 5.0,\n",
       "  'sympathetic': 1.0,\n",
       "  'mechanic': 2.0,\n",
       "  'there': 1.0,\n",
       "  'performed': 1.0,\n",
       "  'visual': 1.0,\n",
       "  'this': 3.0,\n",
       "  'stunning': 1.0,\n",
       "  'wwii': 1.0,\n",
       "  'throne': 1.0,\n",
       "  'blind': 1.0,\n",
       "  'score': 1.0,\n",
       "  'then': 2.0,\n",
       "  'fantastic': 2.0,\n",
       "  'br': 2.0,\n",
       "  'ahamd': 1.0,\n",
       "  'thief': 2.0,\n",
       "  'caused': 1.0,\n",
       "  'thanks': 1.0,\n",
       "  'little': 1.0,\n",
       "  'menzies': 1.0,\n",
       "  'figure': 1.0,\n",
       "  'cinematography': 2.0,\n",
       "  'hands': 1.0,\n",
       "  'bow': 1.0,\n",
       "  'others': 1.0,\n",
       "  'remarkable': 1.0,\n",
       "  'the': 18.0,\n",
       "  'cannon': 1.0,\n",
       "  'ranks': 1.0,\n",
       "  'finest': 1.0,\n",
       "  'time': 1.0,\n",
       "  'usa': 1.0,\n",
       "  's': 1.0,\n",
       "  'directed': 1.0,\n",
       "  'perinal': 1.0,\n",
       "  'ludwing': 1.0,\n",
       "  'with': 4.0,\n",
       "  'picture': 1.0,\n",
       "  'michael': 1.0,\n",
       "  'powell': 1.0,\n",
       "  'tale': 1.0,\n",
       "  'whelan': 1.0,\n",
       "  'is': 4.0,\n",
       "  'colorado': 1.0,\n",
       "  'screenplay': 1.0,\n",
       "  'malleson': 1.0,\n",
       "  'dialogs': 1.0,\n",
       "  'also': 1.0,\n",
       "  'writer': 1.0,\n",
       "  'rex': 1.0,\n",
       "  'fond': 1.0,\n",
       "  'outbreak': 1.0,\n",
       "  'buffs': 1.0,\n",
       "  'setting': 1.0,\n",
       "  'paralyzing': 1.0,\n",
       "  'plenty': 1.0,\n",
       "  'filming': 1.0,\n",
       "  'vizier': 1.0,\n",
       "  'oscars': 1.0,\n",
       "  'kali': 1.0,\n",
       "  'musical': 1.0,\n",
       "  'design': 1.0,\n",
       "  'shooting': 1.0,\n",
       "  'collaborators': 1.0,\n",
       "  'fim': 1.0,\n",
       "  'traveled': 1.0,\n",
       "  'especial': 1.0,\n",
       "  'on': 1.0,\n",
       "  'grand': 1.0,\n",
       "  'haunted': 1.0,\n",
       "  'splendid': 1.0,\n",
       "  'technicolor': 1.0,\n",
       "  'fx': 1.0,\n",
       "  'tim': 1.0,\n",
       "  'production': 1.0,\n",
       "  'william': 1.0,\n",
       "  'osmond': 1.0,\n",
       "  'remastering': 1.0,\n",
       "  'vincent': 1.0,\n",
       "  'among': 1.0,\n",
       "  'george': 1.0,\n",
       "  'special': 1.0,\n",
       "  'borradaile': 1.0,\n",
       "  'dated': 1.0,\n",
       "  'urgent': 1.0,\n",
       "  'he': 1.0,\n",
       "  'necessary': 1.0,\n",
       "  'definitively': 1.0,\n",
       "  'immense': 1.0,\n",
       "  'colossal': 1.0,\n",
       "  'biro': 1.0,\n",
       "  'colors': 1.0,\n",
       "  'abu': 2.0,\n",
       "  'worn': 1.0,\n",
       "  'furthermore': 1.0,\n",
       "  'nomination': 1.0,\n",
       "  'miklos': 1.0,\n",
       "  'but': 1.0,\n",
       "  'rozsa': 1.0},\n",
       " 'predictions': 1.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['predictions'] = model.predict(movies, output_type='probability')\n",
    "movies.sort('predictions')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"Even duller, if possible, than the original (I hope I may say that under the IMDb guidelines). THE FRENCH CONNECTION at least tried to absorb European influences, to complicate the conventional view of the American police detective, even if the attempt was foundered by Friedkin's ambivalence, Americaness and general indirection. The (relative) arthouse boom of the 1960s (especially with the nouvelle vague) allowed for a huge influence of European cinema in Hollywood. This lent a new vigour and complexity to a weary medium, and, in the best of them (eg BONNIE AND CLYDE, early Scorcese), a new subversion of received practice. The original CONNECTION was part of this movement, with its difficultly distanced style, and anti-detective figure. TWO is old Hollywood's right-wing reassertion of American values.<br /><br />This is figured in the film's very tiresome America vs France dialectic. For instance, TWO is shot like a 70s French policier. It was the French, of course, who insisted on the greatness of American movies when they were ignored at home, and this, in a sense, is a reclamation, a warning against Gallic presumption. This can be seen in the pattern of the two movies. CONNECTION has French gangsters invading New York, with the French style smothering the American thriller - this leads to the dissolution of the detective figure, and irresolution of plot - the baddie got away. <br /><br />TWO has the American returning to France, with American thriller values imposed on the native genre - the power of the detective is reasserted and conventional resolution is achieved. This is further dramatised in Doyle's relationship with French inspector Barthelmy, whose dominant influence he must shake off before he can control the plot.<br /><br />TWO seems to follow the original by undermining its detective hero. From the start, Doyle's importance is diminished at every turn. Despite the ending of CONNECTION, he is considered a hero. But he is an American in a foreign land, and his inability to control language or customs means he cannot dominate the plot. He even misreads the signs of the police force, mistaking an informer for a criminal, and getting him killed. <br /><br />A detective's power comes from his power as subject to see and interpret, but Doyle spends much of the movie being watched, controlled, an object, a body (literally in the scenes after he is dumped by Charnier) to be viewed and interpreted. In CONNECTION, he instigated the action, chasing the criminals, forcing the plot; here he is passive, tied to a bed, locked in a cell, an addict, a dependent.<br /><br />This loss of phallic power is predictably symbolised in the loss of his gun, and the film follows a depressingly familiar Oedipal trajectory. In the heroin sequences, he is comforted by an old lady who says he looks like her son. His drugged state is like a return to the womb, robbed of adult pressures. Her taking his watch reinforces the timelessness of this state, doubly significant for a man whose career depends on timetables and precision.<br /><br />Oedipus was the first detective, and to avoid his fate, Doyle must reject this false mother who is dissolving his unified identity, and kill the father (Charnier) so that he can take his accepted masculine role in society. Psychoanalytic theory was popular among academics in the 70s(ironically instigated by a Frenchman, Jacques Lacan), but it's rare to see a film so literally full of it. <br /><br />If all of these facts tended towards the minimising of Doyle, then the film's style doesn't. Friedkin distanced us from his hero by refusing empathy or character motivation, focusing on the mechanics of plot. Here, Doyle is a very conventional Hollywood hero. Instead of being lost in murky long shot, he is made knowable and understandable to the viewer with the traditional devices - point-of-view shots, close ups, connecting shots etc.<br /><br />TWO is all about the fall and rise of Popeye Doyle. Plot in this case is subservient to the acting, which is the usual Hackman showiness. The cold turkey scenes, therefore, despite their tediousness, are not disturbing. We are allowed to share rather than coldly observe; this a far less discomforting experience. The scenes are also shot through with a lachrymose manly sentimentality that is very American. <br /><br />So while CONNECTION tried to imitate the complex thrillers of Jean Pierre Melville, TWO does the complete opposite. Melville's LE SAMOURAI featured a gangster who started the film whole, powerful, outside language, and charted his eventual disintegration. TWO starts with a disintegrated character, achieved partly through inability with language, whose dominance begins when he steps outside language - the concluding action sequences are largely wordless. <br /><br />In the film, the locale and language are important as they fixed and undermined the detective, but as he regains his power (figured in the return of his gun, and the cathartic burning of the primal site of vulnerability, the tower block where Charnier held him), the Marseilles setting becomes more irrelevant, and the mythic stand-off, which could take place anywhere, takes over. Compare the endings of the two films: one admits ambiguity and despair, the other absolute certainty.<br /><br />\",\n",
       " 'sentiment': 'negative',\n",
       " 'words': {'despair': 1.0,\n",
       "  'ambiguity': 1.0,\n",
       "  'admits': 1.0,\n",
       "  'one': 1.0,\n",
       "  'endings': 1.0,\n",
       "  'compare': 1.0,\n",
       "  'takes': 1.0,\n",
       "  'could': 1.0,\n",
       "  'as': 3.0,\n",
       "  'less': 1.0,\n",
       "  'other': 1.0,\n",
       "  'whole': 1.0,\n",
       "  'signs': 1.0,\n",
       "  'policier': 1.0,\n",
       "  'every': 1.0,\n",
       "  'misreads': 1.0,\n",
       "  'through': 2.0,\n",
       "  'dominate': 1.0,\n",
       "  'means': 1.0,\n",
       "  'killed': 1.0,\n",
       "  'or': 2.0,\n",
       "  'popular': 1.0,\n",
       "  'language': 5.0,\n",
       "  'foreign': 1.0,\n",
       "  'movies': 2.0,\n",
       "  'an': 5.0,\n",
       "  'adult': 1.0,\n",
       "  'despite': 2.0,\n",
       "  'indirection': 1.0,\n",
       "  'start': 1.0,\n",
       "  'undermining': 1.0,\n",
       "  'absolute': 1.0,\n",
       "  'mistaking': 1.0,\n",
       "  'reassertion': 1.0,\n",
       "  'etc': 1.0,\n",
       "  'lacan': 1.0,\n",
       "  'regains': 1.0,\n",
       "  'before': 1.0,\n",
       "  'style': 3.0,\n",
       "  'inability': 2.0,\n",
       "  'york': 1.0,\n",
       "  'primal': 1.0,\n",
       "  'must': 2.0,\n",
       "  'whose': 3.0,\n",
       "  'him': 2.0,\n",
       "  'certainty': 1.0,\n",
       "  'inspector': 1.0,\n",
       "  'cell': 1.0,\n",
       "  'relationship': 1.0,\n",
       "  'new': 3.0,\n",
       "  'turkey': 1.0,\n",
       "  'further': 1.0,\n",
       "  'theory': 1.0,\n",
       "  'these': 1.0,\n",
       "  'genre': 1.0,\n",
       "  'getting': 1.0,\n",
       "  'hero': 4.0,\n",
       "  'imposed': 1.0,\n",
       "  'returning': 1.0,\n",
       "  'irresolution': 1.0,\n",
       "  'take': 2.0,\n",
       "  'leads': 1.0,\n",
       "  'experience': 1.0,\n",
       "  'pattern': 1.0,\n",
       "  'seen': 1.0,\n",
       "  'becomes': 1.0,\n",
       "  'be': 2.0,\n",
       "  'it': 3.0,\n",
       "  'achieved': 2.0,\n",
       "  'is': 22.0,\n",
       "  'presumption': 1.0,\n",
       "  'they': 2.0,\n",
       "  'absorb': 1.0,\n",
       "  'movie': 1.0,\n",
       "  'bed': 1.0,\n",
       "  'dominant': 1.0,\n",
       "  'on': 4.0,\n",
       "  'burning': 1.0,\n",
       "  'insisted': 1.0,\n",
       "  'subject': 1.0,\n",
       "  'who': 4.0,\n",
       "  'like': 3.0,\n",
       "  'avoid': 1.0,\n",
       "  'when': 2.0,\n",
       "  'attempt': 1.0,\n",
       "  'instance': 1.0,\n",
       "  'off': 2.0,\n",
       "  'melville': 2.0,\n",
       "  'diminished': 1.0,\n",
       "  'general': 1.0,\n",
       "  't': 1.0,\n",
       "  'wing': 1.0,\n",
       "  'film': 6.0,\n",
       "  'in': 18.0,\n",
       "  'cannot': 1.0,\n",
       "  'the': 71.0,\n",
       "  'important': 1.0,\n",
       "  'films': 1.0,\n",
       "  'foundered': 1.0,\n",
       "  'mechanics': 1.0,\n",
       "  'smothering': 1.0,\n",
       "  'vague': 1.0,\n",
       "  'americaness': 1.0,\n",
       "  'anywhere': 1.0,\n",
       "  'forcing': 1.0,\n",
       "  'ambivalence': 1.0,\n",
       "  'sense': 1.0,\n",
       "  's': 9.0,\n",
       "  'doesn': 1.0,\n",
       "  'gallic': 1.0,\n",
       "  'difficultly': 1.0,\n",
       "  'fate': 1.0,\n",
       "  'frenchman': 1.0,\n",
       "  'a': 26.0,\n",
       "  'resolution': 1.0,\n",
       "  'addict': 1.0,\n",
       "  'home': 1.0,\n",
       "  'by': 6.0,\n",
       "  'hope': 1.0,\n",
       "  'detective': 8.0,\n",
       "  'steps': 1.0,\n",
       "  'movement': 1.0,\n",
       "  'nouvelle': 1.0,\n",
       "  'native': 1.0,\n",
       "  '70s': 2.0,\n",
       "  'of': 32.0,\n",
       "  'even': 3.0,\n",
       "  'allowed': 2.0,\n",
       "  'jean': 1.0,\n",
       "  'old': 2.0,\n",
       "  'dialectic': 1.0,\n",
       "  'criminal': 1.0,\n",
       "  'police': 2.0,\n",
       "  'ending': 1.0,\n",
       "  'european': 2.0,\n",
       "  'conventional': 3.0,\n",
       "  'at': 3.0,\n",
       "  'usual': 1.0,\n",
       "  'doyle': 7.0,\n",
       "  'medium': 1.0,\n",
       "  'huge': 1.0,\n",
       "  'viewer': 1.0,\n",
       "  'complicate': 1.0,\n",
       "  'watch': 1.0,\n",
       "  'see': 2.0,\n",
       "  'can': 3.0,\n",
       "  'after': 1.0,\n",
       "  'gangsters': 1.0,\n",
       "  'reclamation': 1.0,\n",
       "  'devices': 1.0,\n",
       "  'i': 2.0,\n",
       "  'vulnerability': 1.0,\n",
       "  'informer': 1.0,\n",
       "  'locked': 1.0,\n",
       "  'if': 3.0,\n",
       "  'view': 2.0,\n",
       "  'connecting': 1.0,\n",
       "  'were': 1.0,\n",
       "  'duller': 1.0,\n",
       "  'shake': 1.0,\n",
       "  'criminals': 1.0,\n",
       "  'reasserted': 1.0,\n",
       "  'cold': 1.0,\n",
       "  'got': 1.0,\n",
       "  'role': 1.0,\n",
       "  'american': 8.0,\n",
       "  'say': 1.0,\n",
       "  'this': 12.0,\n",
       "  'imdb': 1.0,\n",
       "  'was': 5.0,\n",
       "  'comes': 1.0,\n",
       "  'baddie': 1.0,\n",
       "  'subservient': 1.0,\n",
       "  'influences': 1.0,\n",
       "  'thrillers': 1.0,\n",
       "  'least': 1.0,\n",
       "  'right': 1.0,\n",
       "  'arthouse': 1.0,\n",
       "  'customs': 1.0,\n",
       "  'hollywood': 3.0,\n",
       "  'may': 1.0,\n",
       "  'reinforces': 1.0,\n",
       "  'oedipus': 1.0,\n",
       "  'connection': 6.0,\n",
       "  'therefore': 1.0,\n",
       "  'french': 6.0,\n",
       "  'depressingly': 1.0,\n",
       "  'with': 9.0,\n",
       "  'away': 1.0,\n",
       "  'for': 4.0,\n",
       "  'gangster': 1.0,\n",
       "  'than': 2.0,\n",
       "  'dumped': 1.0,\n",
       "  'possible': 1.0,\n",
       "  'cathartic': 1.0,\n",
       "  'part': 1.0,\n",
       "  'cinema': 1.0,\n",
       "  'lent': 1.0,\n",
       "  'its': 2.0,\n",
       "  'considered': 1.0,\n",
       "  'boom': 1.0,\n",
       "  'vigour': 1.0,\n",
       "  'influence': 2.0,\n",
       "  'complexity': 1.0,\n",
       "  'to': 17.0,\n",
       "  'much': 1.0,\n",
       "  'weary': 1.0,\n",
       "  'dependent': 1.0,\n",
       "  'has': 2.0,\n",
       "  'timetables': 1.0,\n",
       "  'them': 1.0,\n",
       "  'tried': 2.0,\n",
       "  'pierre': 1.0,\n",
       "  'warning': 1.0,\n",
       "  'relative': 1.0,\n",
       "  'eg': 1.0,\n",
       "  'coldly': 1.0,\n",
       "  'greatness': 1.0,\n",
       "  'vs': 1.0,\n",
       "  'timelessness': 1.0,\n",
       "  'clyde': 1.0,\n",
       "  'object': 1.0,\n",
       "  'early': 1.0,\n",
       "  'invading': 1.0,\n",
       "  'especially': 1.0,\n",
       "  'two': 9.0,\n",
       "  'scorcese': 1.0,\n",
       "  'guidelines': 1.0,\n",
       "  'power': 5.0,\n",
       "  'friedkin': 2.0,\n",
       "  'depends': 1.0,\n",
       "  'anti': 1.0,\n",
       "  'control': 2.0,\n",
       "  'figured': 2.0,\n",
       "  'close': 1.0,\n",
       "  'masculine': 1.0,\n",
       "  'plot': 6.0,\n",
       "  'accepted': 1.0,\n",
       "  'bonnie': 1.0,\n",
       "  'original': 3.0,\n",
       "  'father': 1.0,\n",
       "  'values': 2.0,\n",
       "  'importance': 1.0,\n",
       "  'dissolving': 1.0,\n",
       "  'dramatised': 1.0,\n",
       "  'academics': 1.0,\n",
       "  'case': 1.0,\n",
       "  'interpret': 1.0,\n",
       "  'largely': 1.0,\n",
       "  'spends': 1.0,\n",
       "  'being': 2.0,\n",
       "  'watched': 1.0,\n",
       "  'comforted': 1.0,\n",
       "  'controlled': 1.0,\n",
       "  'body': 1.0,\n",
       "  'understandable': 1.0,\n",
       "  'literally': 2.0,\n",
       "  'dominance': 1.0,\n",
       "  'viewed': 1.0,\n",
       "  'taking': 1.0,\n",
       "  'interpreted': 1.0,\n",
       "  'mythic': 1.0,\n",
       "  'disintegrated': 1.0,\n",
       "  'instigated': 2.0,\n",
       "  'turn': 1.0,\n",
       "  'america': 1.0,\n",
       "  'action': 2.0,\n",
       "  'ironically': 1.0,\n",
       "  'place': 1.0,\n",
       "  'chasing': 1.0,\n",
       "  'ignored': 1.0,\n",
       "  'here': 2.0,\n",
       "  'passive': 1.0,\n",
       "  'doubly': 1.0,\n",
       "  'tied': 1.0,\n",
       "  'loss': 2.0,\n",
       "  'return': 2.0,\n",
       "  'best': 1.0,\n",
       "  'practice': 1.0,\n",
       "  'phallic': 1.0,\n",
       "  'predictably': 1.0,\n",
       "  'gun': 2.0,\n",
       "  'follows': 1.0,\n",
       "  'familiar': 1.0,\n",
       "  'and': 24.0,\n",
       "  'trajectory': 1.0,\n",
       "  'subversion': 1.0,\n",
       "  'lady': 1.0,\n",
       "  'point': 1.0,\n",
       "  'charnier': 3.0,\n",
       "  'observe': 1.0,\n",
       "  'seems': 1.0,\n",
       "  'looks': 1.0,\n",
       "  'her': 2.0,\n",
       "  'son': 1.0,\n",
       "  'drugged': 1.0,\n",
       "  'against': 1.0,\n",
       "  'state': 2.0,\n",
       "  'force': 1.0,\n",
       "  'womb': 1.0,\n",
       "  'psychoanalytic': 1.0,\n",
       "  'robbed': 1.0,\n",
       "  '1960s': 1.0,\n",
       "  'significant': 1.0,\n",
       "  'man': 1.0,\n",
       "  'precision': 1.0,\n",
       "  'first': 1.0,\n",
       "  'reject': 1.0,\n",
       "  'false': 1.0,\n",
       "  'identity': 1.0,\n",
       "  'kill': 1.0,\n",
       "  'society': 1.0,\n",
       "  'hackman': 1.0,\n",
       "  'disturbing': 1.0,\n",
       "  'among': 1.0,\n",
       "  'concluding': 1.0,\n",
       "  'jacques': 1.0,\n",
       "  'symbolised': 1.0,\n",
       "  'powerful': 1.0,\n",
       "  'rare': 1.0,\n",
       "  'refusing': 1.0,\n",
       "  'outside': 2.0,\n",
       "  'full': 1.0,\n",
       "  'showiness': 1.0,\n",
       "  'knowable': 1.0,\n",
       "  'his': 12.0,\n",
       "  'all': 2.0,\n",
       "  'facts': 1.0,\n",
       "  'sequences': 2.0,\n",
       "  'shot': 3.0,\n",
       "  'unified': 1.0,\n",
       "  'tended': 1.0,\n",
       "  'minimising': 1.0,\n",
       "  'over': 1.0,\n",
       "  'then': 1.0,\n",
       "  'us': 1.0,\n",
       "  'empathy': 1.0,\n",
       "  'figure': 2.0,\n",
       "  'motivation': 1.0,\n",
       "  'he': 15.0,\n",
       "  'focusing': 1.0,\n",
       "  'towards': 1.0,\n",
       "  'instead': 1.0,\n",
       "  'oedipal': 1.0,\n",
       "  'so': 3.0,\n",
       "  'eventual': 1.0,\n",
       "  'murky': 1.0,\n",
       "  'heroin': 1.0,\n",
       "  'le': 1.0,\n",
       "  'long': 1.0,\n",
       "  'made': 1.0,\n",
       "  'thriller': 2.0,\n",
       "  'traditional': 1.0,\n",
       "  'scenes': 3.0,\n",
       "  'shots': 2.0,\n",
       "  'ups': 1.0,\n",
       "  'lachrymose': 1.0,\n",
       "  'about': 1.0,\n",
       "  'fall': 1.0,\n",
       "  'popeye': 1.0,\n",
       "  'acting': 1.0,\n",
       "  'also': 1.0,\n",
       "  'which': 2.0,\n",
       "  'their': 1.0,\n",
       "  'land': 1.0,\n",
       "  'tediousness': 1.0,\n",
       "  'are': 5.0,\n",
       "  'tiresome': 1.0,\n",
       "  'not': 1.0,\n",
       "  'barthelmy': 1.0,\n",
       "  'that': 3.0,\n",
       "  'site': 1.0,\n",
       "  'br': 22.0,\n",
       "  'we': 1.0,\n",
       "  'irrelevant': 1.0,\n",
       "  'character': 2.0,\n",
       "  'rather': 1.0,\n",
       "  'far': 1.0,\n",
       "  'very': 3.0,\n",
       "  'but': 4.0,\n",
       "  'france': 2.0,\n",
       "  'discomforting': 1.0,\n",
       "  'course': 1.0,\n",
       "  'mother': 1.0,\n",
       "  'manly': 1.0,\n",
       "  'sentimentality': 1.0,\n",
       "  'begins': 1.0,\n",
       "  'while': 1.0,\n",
       "  'imitate': 1.0,\n",
       "  'dissolution': 1.0,\n",
       "  'complex': 1.0,\n",
       "  'under': 1.0,\n",
       "  'does': 1.0,\n",
       "  'complete': 1.0,\n",
       "  'opposite': 1.0,\n",
       "  'follow': 1.0,\n",
       "  'samourai': 1.0,\n",
       "  'featured': 1.0,\n",
       "  'rise': 1.0,\n",
       "  'started': 1.0,\n",
       "  'pressures': 1.0,\n",
       "  'disintegration': 1.0,\n",
       "  'starts': 1.0,\n",
       "  'partly': 1.0,\n",
       "  'wordless': 1.0,\n",
       "  'locale': 1.0,\n",
       "  'fixed': 1.0,\n",
       "  'tower': 1.0,\n",
       "  'distanced': 2.0,\n",
       "  'career': 1.0,\n",
       "  'undermined': 1.0,\n",
       "  'share': 1.0,\n",
       "  'block': 1.0,\n",
       "  'says': 1.0,\n",
       "  'where': 1.0,\n",
       "  'received': 1.0,\n",
       "  'held': 1.0,\n",
       "  'lost': 1.0,\n",
       "  'marseilles': 1.0,\n",
       "  'from': 3.0,\n",
       "  'charted': 1.0,\n",
       "  'setting': 1.0,\n",
       "  'more': 1.0,\n",
       "  'stand': 1.0},\n",
       " 'predictions': 3.44160884637482e-66}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.sort('predictions')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the patient of having tooth decay is: 0.6681877721681662\n"
     ]
    }
   ],
   "source": [
    "# Dentist logistic classifier\n",
    "# Given: model = d + 0.5c - 0.8\n",
    "# d -> indicates if patient has had decayed tooth in the past\n",
    "# c -> indicates if patient eats candy\n",
    "# c = 0 indicates paties does not eat candy\n",
    "# c = 1 indicates patient eats candy\n",
    "# d = 0 indicates patient did not have tooth decay treatment in the pst\n",
    "# d = 1 indicates patient had tooth decay treatment in the past\n",
    "# Problem: What is the probability if a patient having tooth decay if she ate candy and was treated\n",
    "# tooth decay in the past?\n",
    "# Solution:\n",
    "# ate candy = c = 1\n",
    "# tooth decay treatment in the past = d = 1\n",
    "# score = w1*x1 + w2*x2 + ... + wn*xn + bias\n",
    "# d = x1\n",
    "# c = x2\n",
    "# w1 = 1\n",
    "# w2 = 0.5\n",
    "# bias = -0.8\n",
    "# score = 1*d + 0.5*c + (-0.8)\n",
    "# score = d + 0.5*c - 0.8\n",
    "# score = 1 + 0.5*1 - 0.8\n",
    "# score = 0.7\n",
    "# probability = sigmoid(score)\n",
    "\n",
    "print(f'The probability of the patient of having tooth decay is: {sigmoid(1 + 0.5 * 1 - 0.8)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for (1,1) is 0.7310585786300049\n",
      "Log loss for (1,1) with label 1 is 0.3132616875182228\n",
      "Before logistic trick w1=2 w2=3 bias=-4\n",
      "After logistic trick w1=2.0268941421369995 w2=3.0268941421369995 bias=-3.9731058578630005\n",
      "Prediction for (1,1) after logistical trick is 0.7466231044754239\n",
      "Log loss for (1,1) with label 1 after logistical trick is 0.29219476672354916\n",
      "Did log log loss decrease? True or False: True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Given:\n",
    "# prediction = sigmoid(2x1 + 3x2 - 4)\n",
    "# x1=1,x2=1 or point(1,1) gives prediction of 0\n",
    "\n",
    "# 1. Calculate the prediction that the model gives to the point p\n",
    "# p = (1, 1)\n",
    "point_1_1_prediction = sigmoid(2*1 + 3*1 - 4)\n",
    "print(f'Prediction for (1,1) is {point_1_1_prediction}')\n",
    "\n",
    "# 2. Calculate the log loss of the model produces at point p\n",
    "# log loss = -label * ln(pred) - (1-label) * ln(1-pred)\n",
    "old_log_loss = -1 * math.log(point_1_1_prediction) - (1 - 1) * math.log(1 - point_1_1_prediction)\n",
    "print(f'Log loss for (1,1) with label 1 is { old_log_loss }')\n",
    "\n",
    "# 3. Use the logistic trick to obtain a new model that produces a smaller log loss.\n",
    "# You can use n = 0.1 as the learning rate.\n",
    "# logistic trick\n",
    "# wi^ += (label - pred) * xi * learning_rate\n",
    "# bias^ += (label - pred) * learning_rate\n",
    "# model = 2x1 + 3x2 - 4\n",
    "n = 0.1\n",
    "w1 = 2\n",
    "w2 = 3\n",
    "bias = -4\n",
    "print(f'Before logistic trick w1={w1} w2={w2} bias={bias}')\n",
    "\n",
    "w1 += (1 - point_1_1_prediction) * 1 * n\n",
    "w2 += (1 - point_1_1_prediction) * 1 * n\n",
    "bias += (1 - point_1_1_prediction) * n\n",
    "\n",
    "print(f'After logistic trick w1={w1} w2={w2} bias={bias}')\n",
    "\n",
    "# 4. Find the prediction given by the new model at the point p, and verify that the log loss obtained is smaller than the original\n",
    "# Point(1,1) so x1 = 1, x2=1\n",
    "x1 = 1\n",
    "x2 = 1\n",
    "label = 1\n",
    "point_1_1_prediction_new = sigmoid(w1*x1 + w2*x2 + bias)\n",
    "new_log_loss = -label * math.log(point_1_1_prediction_new) - (1 - label) * math.log(1 - point_1_1_prediction_new)\n",
    "\n",
    "print(f'Prediction for (1,1) after logistical trick is {point_1_1_prediction_new}')\n",
    "print(f'Log loss for (1,1) with label 1 after logistical trick is {new_log_loss}')\n",
    "print(f'Did log log loss decrease? True or False: {new_log_loss < old_log_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for 0.8 prediction is: 1.3862943611198908\n",
      "If x2 = 1, then x1 will be 1.1507784389700189\n",
      "If x1 = 1, then x2 will be 1.1009655179064601\n"
     ]
    }
   ],
   "source": [
    "# Using the updated model above, find a point for which the prediction is 0.8\n",
    "# y^ = sigmoid(score)\n",
    "# sigmoid(score) = 1 / 1 + e ** -score\n",
    "# y^ = 1 / 1 + e ** -score\n",
    "# (1 + e ** -score) * y^ = 1\n",
    "# y^ + y^e**-score = 1\n",
    "# y^e**-score = 1 - y^\n",
    "# e**-score = 1 - y^ / y^\n",
    "# ln(e ** a) = a\n",
    "# ln(e**-score) = ln( 1 - y^ / y^)\n",
    "# -score = ln(1 - y^ / y^)\n",
    "# score = -ln(1 - y^ / y^)\n",
    "# -ln(a) = ln(1 / a)\n",
    "# score = ln( 1 / 1 - y^ / y^)\n",
    "# score = ln(y^ / 1 - y^)\n",
    "\n",
    "score_with_point_8_prediction = math.log(0.8 / (1 - 0.8))\n",
    "print(f'The score for 0.8 prediction is: {score_with_point_8_prediction}')\n",
    "\n",
    "# Given that score = w1x1 + w2x2 + bias\n",
    "# x1 = (score - w2x2 - bias) / w1\n",
    "# x2 = (score - w1x1 - bias) / w2\n",
    "\n",
    "print(f'If x2 = 1, then x1 will be { (score_with_point_8_prediction - w2 * 1 - bias) / w1}')\n",
    "print(f'If x1 = 1, then x2 will be { (score_with_point_8_prediction - w1 * 1 - bias) / w2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
